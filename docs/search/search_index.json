{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"The DS2 Software Documentation","text":"<p>To simplify the understanding of DS2 modules and the reference architecture, the modular components of DS2 have been divided into Tiers.</p>"},{"location":"#tier-0-ds2-support-orientated","title":"Tier 0: DS2 Support Orientated","text":"<p>These represent a range of modules that are perceived as cross-cutting to the other tiers and their modules.</p>"},{"location":"#tier-1-ds2-marketplace-and-deployment-orientated","title":"Tier 1: DS2 Marketplace and Deployment orientated","text":"<p>These support the acquisition, porting, and deployment of modules at participants or service intermediaries</p>"},{"location":"#tier-2-ds2-in-data-space-enablement","title":"Tier 2: DS2 In-Data Space Enablement","text":"<p>The modules facilitate consumer -provider participants in sharing their data. The modules are in general used by a single participant only in their local environment but in some cases, there are additional features to be used between data provider and consumer.</p>"},{"location":"#tier-3-ds2-inter-data-space-enablement","title":"Tier 3: DS2 Inter Data Space Enablement","text":"<p>To an extent, the logic for this layer is the reverse of tier 2.  These modules can be allocated to the Tier 2 situation but their added value is much greater in a cross-sector, cross dataspace scenario. </p>"},{"location":"modules/clm/","title":"Culture and Language","text":""},{"location":"modules/dshare/","title":"Data Share Controller","text":""},{"location":"modules/idm/","title":"Identity Management","text":""},{"location":"modules/idt/","title":"IDT Broker","text":""},{"location":"modules/idt/#general-description","title":"General Description","text":"<p>IDT is the core enabler of DS2 who purpose is to be deployed in front of participants data source/spaces and network connected to any other IDT-enabled data source. As such its aim is to run all DS2 modules, including the DS2 Connector, the core module for Inter-Dataspace communication and data transfer, and the Containerisation module for DS2 module deployment. The IDT contains the core Kubernetes runtime to run all containerised modules and a series of additional open-source software for module management.</p> <p>The IDT contains the Kubernetes runtime that is the core service to run all modules in a containerised way. Those modules descriptors are uploaded to the DS2 Portal Marketplace and then, using the IDT Kubernetes UI, are deployed to the Kubernetes runtime. The Containerisation module kicks-in and then converts those module descriptors to full module charts effectively deploying the DS2 modules. The Kubernetes UI, alongside the Management and Monitoring Controller, will be used to manage and monitor all DS modules running on a participants IDT. Additional services will also be run as part of the IDT such as certificate management, ingress network traffic management using traditional ingress controllers with ingress resources to expose modules and eventually transitioning to service mesh and gateway API, storage management and possibly other useful open-source tools. The other key component of the IDT is the DS2 Connector used for Dataspace like communications following current IDSA and Gaia-X standards. An additional IDT UI will be provided for module navigation and Connector management.</p>"},{"location":"modules/idt/#component-definition","title":"Component Definition","text":"<p>The figure below represents the actors, internal structure, primary sub-components, primary DS2 module interfaces, and primary other interfaces of the module. </p> <p>This module has the following subcomponent and other functions:</p> <ul> <li> <p>Kubernetes (Module Runtime): Kubernetes is the leading technology in container orchestration and the choice and key component of the IDT for deployment and integration of the DS2 modules. This is the core IDT subcomponent that runs and orchestrates the DS2 modules and all the other IDT subcomponents, as containers. This is Open-Source software and the current distribution being used is K3s, a lightweight version of Kubernetes easy to install, half the memory, all in a binary, in less than 100 MB among other enhancements. One of the main advantages is the flexibility of installation, since it can be deployed at a participant edge, onPremise, InCloud, etc.</p> </li> <li> <p>Kubernetes UI: The Kubernetes UI is open-source software based on Rancher that allows to deploy and manage Kubernetes in a more user-friendly way both onPremise and InCloud. The Kubernetes UI will provide the management interface for platform administrators and the module deployment interface for participants running the IDT. This interface will be used to deploy the module ChartDescriptors,  configuration files that describe how a module runs on Kubernetes, from the DS2 Portal Marketplace in the IDT. The Containerisation module will then transform the descriptors into full Helm Charts and deploy them to the Kubernetes subcomponent. The Kubernetes UI will also provide the monitoring interface to the IDT Kubernetes subcomponent and the DS2 modules.</p> </li> <li> <p>Management and Monitoring Controller: This is the main interface from the Kubernetes UI to the Kubernetes subcomponent and also for external integrations. The Management and Monitoring Controller is open-source software based on the Kubernetes and Rancher API and the Rancher agents. It is used as the primary interface to the IDT Kubernetes subcomponent for management and deployment of modules. It will also be used as the primary interface for monitoring which will potentially be integrated with the DRM Blockchain module for traceability. In addition, further research on using other modules for monitoring such as Prometheus-Grafana will be conducted for enhanced monitoring.</p> </li> <li> <p>Ingress \u2013 Gateway: The ingress or gateway resource provides the entry point to the IDT Kubernetes subcomponent via the Ingress controller, thus, the IDT network, for all network traffic from external apps, being an external app, any system external to the IDT. It describes how the DS2 modules are exposed outside of the IDT. Initially the modules will use a Kubernetes Ingress resource to expose the modules but further research will be conducted to examine the use of the Gateway API and Service Mesh technology.</p> </li> <li> <p>Ingress Controller \u2013 Service Mesh: Based on Open Source, the Ingress Controller is the Kubernetes controller dealing with Ingress resources, that is, managing the entry point to the IDT and how the DS2 modules are exposed outside of IDT. Further research is expected for replacement of the Ingress Controller with Service Mesh technology and the Kubernetes Gateway API, that adds a transparent layer to provide the IDT with enhanced connectivity, security, control and observability. The use of the Service Mesh could also be a key feature for using more secure communication via mutual TLS protocol (mTLS) in all DS2 communications which provides and additional trust layer. This could also be integrated with the DS2 trust and identity system.</p> </li> <li> <p>Storage Manager: Open-source software to provide the interface between the IDT Kubernetes subcomponent and the physical storage for DS2 stateful modules. This will use Kubernetes native storage technology to allow highly available stateful module deployments in IDT. When data from DS2 modules need to be persisted in a participant backend storage system, the Storage Manager will be used to map current deployment and Kubernetes Persistent Volumes to external storage systems. This is not a storage system or technology for modules\u2026 If DS2 modules need to use storage, the DS2 modules need to provide them by packaging them in their module Chart.</p> </li> <li> <p>CertManager: Based on Open-source software, it provides management of SSL certificates for secure connectivity ie. HTTPS, with verified signed certificates using Let\u2019s Encrypt CertificateAuthority (CA) and configures them for the Ingress or Gateway resource. The CertManager integrates with the Ingress Controller and/or Service Mesh subcomponents and in addition, further research on integration with DS2 Trust system will be explored.</p> </li> <li> <p>DS2 Connector: The DS2 Connector in the IDT is the key element that will allow for DS2 transactions and data exchange, following the IDSA and Gaia-X standards. The Open-source Eclipse EDC Connector (or the Tractus-X extension) will be used to provide interoperability between Dataspaces and secure, trustworthy exchange of data. Following existing Dataspace principles and protocols, the DS2 Connector will use the DS2 Trust system for identity management and will connect to other participants IDT DS2 Connectors in other Dataspaces for data exchange. The Connector will also integrate with the DS2 Catalog or a Dataspace level Metadata Broker for participant and data discovery. </p> </li> <li> <p>Local Identity: This module is optional and it provides local identity, authentication and authorization to access a participant IDT and its modules by the various users types within a company. Based on Open Source Keycloak identity provider software, further research will be done in order to explore the possibility of linking the Local Identity with the DS2 Trust system.</p> </li> <li> <p>Tier 0 Support Service Stack:</p> <ul> <li>DRM and API: For further exploration integration of the monitoring controller with the Blockchain will be considered.</li> </ul> </li> <li> <p>Tier 1 Service Stack for Marketplace and deployment and API: The full stack will be implemented as generically described elsewhere in this document. Exceptions: The IDT uses the DS2 Portal and Marketplace to retrieve the ChartDescriptors of modules and deploy them via the Kubernetes UI. Then the Containerisation module uses the descriptors to deploy the full module Helm Chart. In addition, The DS2 Connector in the IDT integrates with other IDT DS2 Connectors for data exchange.</p> </li> <li> <p>Tier 3 Trust Stack and Catalog and API: The IDT will make use of the relevant parts of the DS2 Trust Stack for certificates in the Ingress Controller \u2013 Service Mesh and identities in the DS2 Connector. The IDT will also connect via the DS2 Connector to the Catalog.</p> </li> <li> <p>External Apps: External Apps refer to any software application external to the IDT and DS2 ecosystem that uses the DS2 Connector in the IDT for any DS2 data transaction. It\u2019s the application that can trigger a data exchange via the Connector, either as a consumer or producer.</p> </li> <li> <p>External Storage Systems: This refers to any external storage system, physical or software defined, that a participant has already in place and where data from the IDT and DS2 ecosystem can be persisted, thus, is mapped via the Storage Manager into the IDT Kubernetes</p> </li> </ul>"},{"location":"modules/idt/#screenshots","title":"Screenshots","text":"<p>Display an animated gif with 4 representative screenshots of the module</p>"},{"location":"modules/idt/#commercial-information","title":"Commercial Information","text":"<p>Table with some admin information : authors, company, ipr, etc.</p> Organisation (s) License Nature License ICE Open Source Apache 2.0"},{"location":"modules/idt/#top-features","title":"Top Features","text":"<p>Add 8 - 12 relevant features of the module</p> <ol> <li>Kubernetes Platform: The IDT provides a Kubernetes based platform for ease of integration and deployment of the modules</li> <li>Flexible Installation Process: The IDT provides a user friendly installation process for easy installation to non-experienced users.    In any case, management of the platform itself, will require some expertise. In addition, it supports different installation modes from on-cloud to on-prem and edge.</li> <li>Management Interface: A Rancher based UI is provided for the Kubernetes cluster management. Management of Kubernetes itself will require some expertise. The Management UI  provides the interface and API for module management : deployment, deletion, upgrade</li> <li>Monitoring of Platfom and Apps: provides the interface and API to monitor the cluster itself and the modules</li> <li>Seamless Integration with Containerisation Deployment: IDT integrates seamlessly with the Containerisation module for ease of module deployment</li> <li>Networking: provides secure networking and connectivity among the installed apps and to and from outside the cluster</li> <li>Log management: ability to retrieve module logs for troubleshooting and debugging</li> <li>Native Storage: provides Kubernetes native storage for stateful applications</li> <li>IDT Portal: provides a local version of the DS2 Portal as the entry point to the IDT, single sign on and module navigation </li> <li>DS2 Connector: the IDT incorporates the DS2 Connector for DS2 data exchange</li> </ol>"},{"location":"modules/idt/#how-to-install","title":"How To Install","text":"<p>The IDT installs a pre-packaged enterprise ready Kubernetes cluster along with some extra features for management and deployment.</p>"},{"location":"modules/idt/#requirements","title":"Requirements","text":"<p>Provision a Linux VM (Ubuntu 18.04 or 20.04) Resources:</p> <p>Kubernetes Node * Minimum: 2 cpu cores, 4 GB RAM and 10 GB disk capacity. * Recommended: 4 cpu cores, 8 GB RAM and 50 GB disk capacity.</p> <p>These numbers may change since a number of IDT components will be deployed, check specific requirements for specific components.</p>"},{"location":"modules/idt/#software","title":"Software","text":"<p>IDT installs these software utilities and specific tested compatible versions:</p> <ul> <li>Docker</li> <li>K3s (Kubernetes)</li> <li>Helm</li> <li>Cert-manager</li> <li>Rancher</li> <li>Creates a self signed certificate to use by the ingress controller</li> <li>Nginx Ingress Controller</li> <li>Nginx docker (load balancer - optional)</li> <li>DS2 Connector (to do)</li> <li>Core DS2 modules (to do)</li> </ul>"},{"location":"modules/idt/#summary-of-installation-steps","title":"Summary of installation steps","text":"<ol> <li>Clone the repo</li> <li>Deploy IDT<ul> <li>Run the command mini-idt.sh nodeip iface as per instructions. This deploys the Kubernetes platform</li> <li>nodeip: the ip of the node</li> <li>iface: the network interface of the node ip</li> </ul> </li> <li>Access Rancher at https://rancher.$nodeip.ds2.sslip.io where $nodeip uses '-' instead of '.' (The domain can be changed if needed)</li> <li>Register the catalog(s)</li> <li>If http access is needed, run patch_nginx.sh</li> <li>Deploy IDT modules from the Rancher UI (Using Containerisation module at a later stage)<ul> <li>Any script required before deploying any component should be in the idt/modules folder</li> <li>Upon deployment of first module import the self-signed certificate in the trusted CA's store</li> </ul> </li> </ol>"},{"location":"modules/idt/#detailed-steps","title":"Detailed steps","text":"<ul> <li> <p>Clone the repository <pre><code>git clone https://github.com/ds2-eu/idt.git\n</code></pre></p> </li> <li> <p>Navigate to idt folder <pre><code>cd idt\n</code></pre></p> </li> <li> <p>Run idt <pre><code>./idt.sh ip iface\n</code></pre> where ip is the ip of the vm where k3s will be installed and iface is the network interface of the nodeip for instance ./idt.sh 192.168.50.5 enp0s8</p> </li> </ul> <p>The script will install the software utilities in this order:</p> <ul> <li> <p>First, IDT installs Docker</p> </li> <li> <p>Then, k3s Kubernetes cluster is installed. Once installed, the installation process will wait and check for K3s to be up and running. Helm is installed together with K3s and kubectl.</p> </li> <li> <p>Next cert-manager is deployed in order to provide a ssl certificate for Rancher. Process will wait and check that cert-manager is running.</p> </li> <li> <p>Then Rancher is deployed in the cluster. Process will wait and check that Rancher is running.</p> </li> <li> <p>Next, the nginx ingress controller is deployed. Before this, a self signed ssl certificate is created using certmanager. Notice that the domain that is configured in the certificate, is the one to be used as domain for the modules when deployed to IDT which defaults to *.$nodeip.modules.ds2.sslip.io . This domain can be changed.</p> </li> <li> <p>DS2 IDT is now ready.</p> </li> </ul> <p></p> <ul> <li>Access Rancher by accessing the Rancher url in the browser (https://rancher.$nodeip.ds2.sslip.io)</li> <li>Once in the Rancher UI, the admin password is set</li> <li>Then navigate to the workloads in the system project</li> </ul> <p></p> <ul> <li> <p>The nginx ingress controller is by default set to only accept https connections and redirect to https. In order to use http, run the script patch_nginx.sh which will configure nginx ingress controller to accept http (optional). </p> </li> <li> <p>Now that the cluster is up and running, the Rancher UI can be accessed in order to manage the cluster and install modules. </p> </li> </ul>"},{"location":"modules/idt/#how-to-use","title":"How To Use","text":"<p>Once the IDT has been installed, the Rancher UI along with the IDT Portal (local Portal) and the core modules (to be done) can be accessed.</p>"},{"location":"modules/idt/#rancher-ui","title":"Rancher UI","text":"<p>The Rancher UI is the main entry point for Kubernetes cluster management and configuration. </p> <ul> <li> <p>Inspect the cluster and check number of nodes, resources, etc       </p> </li> <li> <p>Create a Module Repository: A user can register a module catalog or repository in order to be able to deploy modules from that module repository. A catalog is just a repository, git or helm, where helm charts are stored. In general, users won't need to create any new repository in the IDT since a default DS2 catalog will be created for the organisation pulling from the organisation repository in DS2 intermediary platform.  If needed, in order to create a new repository, navigate to the cluster, apps, repositories, and click on the \"Add Catalog\" button. Fill in the form with the credentials for a private repository and click \"Create\". The Repository is added to Rancher and the modules will be displayed in the Apps view       </p> </li> <li> <p>Module Deployment: modules can be deployed from the registered Repository, but in general this will be done via the Containerisation module. If needed, navigate to Apps, Charts and the list of available charts (apps) is displayed. Select the chart to be deployed, click on Install, select the Namespace and Name for the instance of the chart and select whether to customize the Helm options before install. If customization is selected, fill in the configuration form and or yaml. Click Next then click Install. The application will be deployed to the platform.       </p> </li> <li> <p>Module logs: In order to review the modules logs, navigate to Apps, Installed Apps, and the list of installed modules is displayed. Select the module to be monitored and the list of Kubernees resources of that module are displayed. Select the Deployment and the Pod is displayed. Click on the three dots on the right and select View Logs. The logs of the module are displayed.        </p> </li> <li> <p>Module deletion: modules can be deleted by navigating to Apps, Installed apps and clicking on the three dots on the right and click on Delete. In general, this will be done via the Containerisation module       </p> </li> </ul>"},{"location":"modules/idt/#idt-portal","title":"IDT Portal","text":"<p>To Be Done</p>"},{"location":"modules/idt/#connector-ui","title":"Connector UI","text":"<p>To Be Done</p>"},{"location":"modules/idt/#additional-links","title":"Additional Links","text":"<p>Kubernetes https://v1-26.docs.kubernetes.io/docs/home/</p> <p>Helm https://helm.sh/</p> <p>K3s https://k3s.io/</p> <p>Rancher https://ranchermanager.docs.rancher.com/v2.7/getting-started/quick-start-guides</p> <p>EDC Connector https://eclipse-edc.github.io/</p> <p>Portal Repository https://github.com/ds2-eu/portal (Private Link for Project Members)</p>"},{"location":"modules/orchestration/","title":"Orchestration","text":"Project Links Software GitHub Repository https://github.com/ds2-eu/orchestration Progress GitHub Project https://github.com/orgs/ds2-eu/projects/9"},{"location":"modules/orchestration/#general-description","title":"General Description","text":"<p>To design and then orchestrate at runtime In-Dataspace, Inter-Dataspace, internal, and third-party services which facilitate common data-orientated operations such as transformation of data, checks on data, data updates etc. The orchestrator contains a flexible GUI to design workflows and decision points on these services, and runtime component to implement the workflow.</p> <p>Services are added to and then selected from a Service catalog from a participant\u2019s local service catalog (In-Dataspace deployment), the DS2 service intermediary catalog (Inner-Dataspace), or other available catalog/service knowledge. These services can be graphically linked together to form a workflow and where decision pathways, decision points, and other operators can be deployed to determine the workflow. Error and exit points should be predetermined with defaults ensuring that failures and error conditions allow flows to be closed automatically. One class of operator is for user defined forms for human input but most often the flows contain backend services. In the context of DS2 the operators will, if necessary, be expanded based on novel usecase peculiarities as will the forms designer. Primarily the design interface is orientated around service interconnectivity, but this will be augmented with a data pre-viewer to help interconnect and understand the results of interconnecting data-orientated services. The orchestrator will be available as a module and for interparticipant service orchestration will extend the connectors. </p>"},{"location":"modules/orchestration/#component-definition","title":"Component Definition","text":"<p>The figure below represents the actors, internal structure, primary sub-components, primary DS2 module interfaces, and primary other interfaces of the module. </p> <p>This module has the following subcomponent and other functions:</p>"},{"location":"modules/orchestration/#orchestration-module-core","title":"Orchestration Module - Core","text":"<ul> <li> <p>Orchestration Core: This is the runtime heart of orchestration which conducts a process (workflow) triggering other services and via a BPMN module from the Service Composition designer repository. For the tier 1 standard connections (Portal etc) it can be perceived as the entry point. If new orchestration design methods are needed, it will use them. Runtime events are connected to the logging components and for inter-participant dataflows it will interface with the DS2 Cross Participant Orchestration subcomponent. This is currently ICE background and will see little development except for a DS2 compliant UI.</p> </li> <li> <p>DS2 Service Registry:</p> <ul> <li>In-participant: This is a local registry of all services which a participant may potentially use in a workflow, composed together in the designer,      and executed in the runtime. Registration can be automatic in the case of IDT installed services.      It will also expose services in the inter-participant DS2 registry. The submodule exists now but will be rebuilt in the context of DS2 and IDT. </li> <li>Between Participant: 95% the same functionality but can function similarly to a metadata broker to host services from multiple participants      which can be shared in a controlled way to the In-participant registry to allow participant-participant service interactions </li> </ul> </li> <li> <p>Service Composition Designer (DS2 Upgrade): This is the main UI for the Orchestration Designer based on existing ICE background. It allows a user to select or drag various elements from a toolbox (services/APIs from the DS2 Service Registry, methods), which can be placed on a canvas where they can then begin to start designing their orchestration by dragging and connecting various elements together. The saved BPMN2.0 notation model will then be used by the runtime orchestration core. The DS2 upgrade will be mainly for UI and inclusion of New Data Previewer and Forms designer blocks. </p> </li> <li> <p>Forms designer: Many orchestrations have a need for user input and whilst some might come from other systems this can be complex when only limited information. The forms designer will allow the easy inclusion of simple form in any Service composition and also ensure that it respect the data flow as well as service needs.</p> </li> <li> <p>Data Previewer: This is also a new subcomponent which will be rendered via the Service composition designer. Currently services are connected but when designing it is useful to know at design time what might be the inputs and the expect result. In a data orientated project this is especially useful, and this utility will allow some rendering of data to help show flow operations between building blocks before they are deployed. </p> </li> <li> <p>New Orchestration methods (from pilots): Many methods \u2013 eg choice boxes, selections are already implemented in the orchestrator, but it is possible that the pilot might suggest further ones that could be interesting to implement \u2013 although at this stage of the analysis it seems there is not. The new methods will be exposed in the orchestrator runtime &amp; designer. </p> </li> <li> <p>Orchestration track/log: Currently this is rudimentary and especially in the trustworthy context of dataspace an major overhaul is necessary to extract more granular logging information at runtime.  </p> </li> <li> <p>Services and API: These are the services that can be orchestrated, and the API block is the interface to: </p> <ul> <li>Other External (non DS2) Modules/Services</li> <li>DS Service Intermediaries</li> <li>Tier 2 In dataspace DS Modules/Service:</li> </ul> </li> <li> <p>Tier 0 Support Service Stack:</p> <ul> <li>DRM and API: For further exploration, but if room to implement and a match of requirements to feature the blockchain part of the DRM module  to enhance logging </li> <li>DARC &amp; API: As with DRM but in this case to use DARC to help configuration of the module </li> <li>**Culture and Language Module and API</li> </ul> </li> <li> <p>Tier 1 Service Stack for Marketplace and deployment and API: The full stack will be implemented as generically described elsewhere in this document. Exceptions: The Platform will only be needed for inter-participant service orchestrations if used</p> </li> </ul>"},{"location":"modules/orchestration/#inter-participant-orientated","title":"Inter-Participant orientated","text":"<ul> <li> <p>DS2 Cross Participant Orchestration: This is a new runtime module which will act as a bridge between the orchestration within each participant through interconnections to the Inter-Participant Service Registry and the Orchestration core at each participant </p> </li> <li> <p>DS2 Service Registry: As described above </p> </li> <li> <p>Tier 3 Trust Stack and API: For interparticipant service the module will use relevant parts of the DS2 trust stack</p> </li> </ul>"},{"location":"modules/orchestration/#screenshots","title":"Screenshots","text":"<p>Display a gif with several representative screenshots of the module</p>"},{"location":"modules/orchestration/#commercial-information","title":"Commercial Information","text":"<p>Table with some admin information : authors, company, ipr, etc.</p> Organisation (s) License Nature Licenses i4RI Open Source Apache 2.0"},{"location":"modules/orchestration/#top-features","title":"Top Features","text":"<p>Table with most representative features from the roles, resourcing and milestones table in the module architecture</p>"},{"location":"modules/orchestration/#how-to-install","title":"How To Install","text":"<p>Steps to install the module, first standalone for testing and then with the idt</p>"},{"location":"modules/orchestration/#how-to-use","title":"How To Use","text":"<p>Steps on how to use the different features of the module</p>"},{"location":"modules/orchestration/#additional-links","title":"Additional Links","text":""},{"location":"openAPI/idt/","title":"IDT","text":"<p>This is the document where Open API Spec will be added</p>"}]}